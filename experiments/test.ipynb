{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm here and ready to help. What can I do for you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 13, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None}, id='run-3472316d-22a3-496c-8c97-a2fae56a3cc4-0', usage_metadata={'input_tokens': 13, 'output_tokens': 18, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Openai api with langchain is working\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "OpenAI_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.6, api_key= os.environ['OPENAI_API_KEY'])\n",
    "messages=[(\"Say hello if you are working\")]\n",
    "ai_msg = OpenAI_llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Βασίλης\\AppData\\Local\\Temp\\ipykernel_9244\\1254470714.py:4: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(tools, llm=OpenAI_llm, agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION)\n",
      "C:\\Users\\Βασίλης\\AppData\\Local\\Temp\\ipykernel_9244\\1254470714.py:6: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent.run(\"What is current value of 1 dollar in rupees?\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current value of 1 US dollar is approximately 86.53 Indian Rupees.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing agents with langchain\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "\n",
    "tools = load_tools([\"serpapi\"], llm = OpenAI_llm)\n",
    "agent = initialize_agent(tools, llm=OpenAI_llm, agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION)\n",
    "\n",
    "agent.run(\"What is current value of 1 dollar in rupees?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Add the parent directory of 'config' to sys.path\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "\n",
    "from config import constants\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.6,\n",
    "    api_key= constants.OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Βασίλης\\AppData\\Local\\Temp\\ipykernel_21492\\3732751371.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  conversational_memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferMemory \n",
    "# initialize conversational memory \n",
    "\n",
    "conversational_memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=5,\n",
    "    return_messages = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "import requests\n",
    "import json\n",
    "class GetClientDetails(BaseTool):\n",
    "    name: str = \"Client details extractor\"\n",
    "    description: str = \"use this tool when you have given a platform name, idea or platform link and you want to find more information about CEO of platform and proposed idea\"\n",
    "    def _run(self, website):\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"sonar-pro\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You are artificial intelligence agent which extracts an information by searching about it online\"\n",
    "                        \"and returns information in this format if it exists\"\n",
    "                        \"Title of website or platform: \"\n",
    "                        \"Proposed idea:\"\n",
    "                        \"CEO Information:\"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"I am giving you platform name,idea or platform link and you have to find latest information about\" \n",
    "                        \"the platform by going to given link and return atleast 200 words description about idea and\"\n",
    "                        \"atleast 150 words description about CEO, their goal and achievements\"\n",
    "                        \"Please try to make it as detailed as you can and always refer to online information\"\n",
    "                        \"here is the platform link or name \"\n",
    "                        f\"{str(website)}\"\n",
    "                    )\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"Authorization\":f\"Bearer {constants.PERPLEXITY_API_KEY}\"\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        return response\n",
    "    \n",
    "    def _arun(self, website):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetPlatformInfo(BaseTool):\n",
    "    name: str = \"Platform info extractor\"\n",
    "    description: str = \"use this tool when you have given a description about meeting and you have to find the proposed idea, client name or platform link from given description\"\n",
    "\n",
    "    def _run(self, description):\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"sonar-pro\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You have given a description of meeting and you will have to find out proposed idea, client name and website link mentioned in the given description.\"\n",
    "                        \"Use client info extractor tool to get more information.\"\n",
    "                        \"Return it in this format\"\n",
    "                        \"Idea: <idea>\"\n",
    "                        \"Client Info: <client_info>\"\n",
    "                        \"Platform Link: <platform_link>\"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"if anything is not provided in description then use internet and google search to find out the actual information\"\n",
    "                        \"Here is the meeting description \" \n",
    "                        f\"{str(description)}\"\n",
    "                    )\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"Authorization\":f\"Bearer {constants.PERPLEXITY_API_KEY}\"\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        return response\n",
    "    \n",
    "    def _arun(self, website):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetIdeaSolution(BaseTool):\n",
    "    name: str = \"Solution extractor\"\n",
    "    description: str = \"use this tool when you have given an idea description and information about client and you have to find solution on how we can achieve the given idea\"\n",
    "\n",
    "    def _run(self, description):\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"sonar-pro\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You have given an idea description and you have to find around 3-4 solutions to achieve the given idea using AI-ML\"\n",
    "                        \"or webdev technologies. Search online about tech stack, resources, timeline of project and youtube videos and send it with proper formatting and line breaks in this format\"\n",
    "                        \"Solution: <solution>\"\n",
    "                        \"Tech stack: <tech_stack>\"\n",
    "                        \"Timeline: <timeline>\"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"Here is the idea description \" \n",
    "                        f\"{str(description)}\"\n",
    "                    )\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"Authorization\":f\"Bearer {constants.PERPLEXITY_API_KEY}\"\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=headers)\n",
    "        return response\n",
    "    \n",
    "    def _arun(self, website):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Agent\n",
    "from langchain.agents import initialize_agent\n",
    "tools = [GetClientDetails(), GetPlatformInfo(), GetIdeaSolution()]\n",
    "agent = initialize_agent(\n",
    "    tools=tools, \n",
    "    llm = llm, \n",
    "    agent=\"zero-shot-react-description\", \n",
    "    verbose=True, \n",
    "    max_iterations=3, \n",
    "    early_stopping_method='generate', \n",
    "    memory = conversational_memory, \n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer the question, I need to first extract the idea, client name, and platform link from the given meeting description using the Platform info extractor tool.\n",
      "\n",
      "Action: Platform info extractor\n",
      "Action Input: \"Hey there, myself rohan and we are hosting this meeting to discuss about my idea of making a twitter automation tool with several features like automated tweets, scheduled tweets, tweet improvement guides etc\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m<Response [200]>\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI need to extract the relevant information from the response to proceed with the next steps.\n",
      "\u001b[0m\n",
      "Observation: Invalid Format: Missing 'Action:' after 'Thought:\n",
      "Thought:\u001b[32;1m\u001b[1;3mTo properly proceed, I need to correctly utilize the tools and extract the necessary information step by step. Let's start again.\n",
      "\n",
      "Question: First find the idea, client name and platform link using Platform info extractor tool and find 150 words information about proposed idea about product, goals and achievements of CEO. Once you got the information about their idea then find how we can help them to build it in 200 words fetch realtime data from internet everytime.This information is going to be added in project proposal so please write in detail and sections like CEO_Info, idea and solution must be explained in 600 words each. Return your response in python dict format like below and please use proper line breaks: \n",
      "      {\n",
      "      \"platform_name\": platform_name,\n",
      "      \"CEO_Info\": ceo_info,\n",
      "      \"CEO_Name\": ceo_name,\n",
      "      \"idea\": idea,\n",
      "      \"solution\": solution,\n",
      "      \"tech_stack\": tech stack,\n",
      "      \"timeline\": timeline,\n",
      "      \"Platform_link\": platform_link\n",
      "      }\n",
      "      Here is the description: Hey there, myself rohan and we are hosting this meeting to discuss about my idea of making a twitter automation tool with several features like automated tweets, scheduled tweets, tweet improvement guides etc\n",
      "          \n",
      "Thought: I should use the Platform info extractor tool to get the idea, client name, and platform link from the provided description.\n",
      "\n",
      "Action: Platform info extractor\n",
      "Action Input: \"Hey there, myself rohan and we are hosting this meeting to discuss about my idea of making a twitter automation tool with several features like automated tweets, scheduled tweets, tweet improvement guides etc\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m<Response [200]>\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI apologize for the confusion earlier. Let's proceed with the extraction of information step by step.\n",
      "\n",
      "Question: First find the idea, client name and platform link using Platform info extractor tool and find 150 words information about proposed idea about product, goals and achievements of CEO. Once you got the information about their idea then find how we can help them to build it in 200 words fetch realtime data from internet everytime.This information is going to be added in project proposal so please write in detail and sections like CEO_Info, idea and solution must be explained in 600 words each. Return your response in python dict format like below and please use proper line breaks: \n",
      "      {\n",
      "      \"platform_name\": platform_name,\n",
      "      \"CEO_Info\": ceo_info,\n",
      "      \"CEO_Name\": ceo_name,\n",
      "      \"idea\": idea,\n",
      "      \"solution\": solution,\n",
      "      \"tech_stack\": tech stack,\n",
      "      \"timeline\": timeline,\n",
      "      \"Platform_link\": platform_link\n",
      "      }\n",
      "      Here is the description: Hey there, myself rohan and we are hosting this meeting to discuss about my idea of making a twitter automation tool with several features like automated tweets, scheduled tweets, tweet improvement guides etc\n",
      "          \n",
      "Thought: I should use the Platform info extractor tool to get the idea, client name, and platform link from the provided description.\n",
      "\n",
      "Action: Platform info extractor\n",
      "Action Input: \"Hey there, myself rohan and we are hosting this meeting to discuss about my idea of making a twitter automation tool with several features like automated tweets, scheduled tweets, tweet improvement guides etc\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 21\u001b[0m\n\u001b[0;32m      1\u001b[0m para \u001b[38;5;241m=\u001b[39m agent\u001b[38;5;241m.\u001b[39mrun(\n\u001b[0;32m      2\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFirst find the idea, client name and platform link using Platform info extractor tool and find 150 words information about proposed idea about product, goals and achievements of CEO. Once you got the information about their idea then find how we can help them to build it in 200 words \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfetch realtime data from internet everytime.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     19\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHey there, myself rohan and we are hosting this meeting to discuss about my idea of making a twitter automation tool with several features like automated tweets, scheduled tweets, tweet improvement guides etc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     20\u001b[0m       )\n\u001b[1;32m---> 21\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpara\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(output)\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\json\\__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    341\u001b[0m     s \u001b[38;5;241m=\u001b[39m s\u001b[38;5;241m.\u001b[39mdecode(detect_encoding(s), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msurrogatepass\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    348\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mC:\\Program Files\\Python311\\Lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "para = agent.run(\n",
    "      \"First find the idea, client name and platform link using Platform info extractor tool and find 150 words information about proposed idea about product, goals and achievements of CEO. Once you got the information about their idea then find how we can help them to build it in 200 words \"\n",
    "      \"fetch realtime data from internet everytime.\"\n",
    "      \"This information is going to be added in project proposal so please write in detail and sections like CEO_Info,idea and solution must be explained in 600 words each. \"\n",
    "      \"Return your response in python dict format like below and please use proper line breaks: \"\n",
    "      \"\"\"\n",
    "      {\n",
    "      \"platform_name\": platform_name,\n",
    "      \"CEO_Info\": ceo_info,\n",
    "      \"CEO_Name\": ceo_name,\n",
    "      \"idea\": idea,\n",
    "      \"solution\": solution,\n",
    "      \"tech_stack\": tech stack,\n",
    "      \"timeline\": timeline,\n",
    "      \"Platform_link\": platform_link\n",
    "      }\n",
    "      \"\"\"\n",
    "      \"Here is the description: \"\n",
    "      \"Hey there, myself rohan and we are hosting this meeting to discuss about my idea of making a twitter automation tool with several features like automated tweets, scheduled tweets, tweet improvement guides etc\"\n",
    "      )\n",
    "output = json.loads(para[\"output\"])\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
