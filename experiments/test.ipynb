{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! I'm here and ready to help. What can I do for you today?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 13, 'total_tokens': 31, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_50cad350e4', 'finish_reason': 'stop', 'logprobs': None}, id='run-3472316d-22a3-496c-8c97-a2fae56a3cc4-0', usage_metadata={'input_tokens': 13, 'output_tokens': 18, 'total_tokens': 31, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test Openai api with langchain is working\n",
    "from langchain_openai import ChatOpenAI\n",
    "import os\n",
    "\n",
    "OpenAI_llm = ChatOpenAI(model=\"gpt-4o\", temperature=0.6, api_key= os.environ['OPENAI_API_KEY'])\n",
    "messages=[(\"Say hello if you are working\")]\n",
    "ai_msg = OpenAI_llm.invoke(messages)\n",
    "ai_msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Βασίλης\\AppData\\Local\\Temp\\ipykernel_9244\\1254470714.py:4: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(tools, llm=OpenAI_llm, agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION)\n",
      "C:\\Users\\Βασίλης\\AppData\\Local\\Temp\\ipykernel_9244\\1254470714.py:6: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent.run(\"What is current value of 1 dollar in rupees?\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The current value of 1 US dollar is approximately 86.53 Indian Rupees.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing agents with langchain\n",
    "from langchain.agents import AgentType, initialize_agent, load_tools\n",
    "\n",
    "tools = load_tools([\"serpapi\"], llm = OpenAI_llm)\n",
    "agent = initialize_agent(tools, llm=OpenAI_llm, agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION)\n",
    "\n",
    "agent.run(\"What is current value of 1 dollar in rupees?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from config import constants\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.6,\n",
    "    api_key= constants.OPENAI_API_KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Βασίλης\\AppData\\Local\\Temp\\ipykernel_12580\\3732751371.py:4: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  conversational_memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chains.conversation.memory import ConversationBufferMemory \n",
    "# initialize conversational memory \n",
    "\n",
    "conversational_memory = ConversationBufferMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=5,\n",
    "    return_messages = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import BaseTool\n",
    "import requests\n",
    "import json\n",
    "class GetClientDetails(BaseTool):\n",
    "    name: str = \"Client details extractor\"\n",
    "    description: str = \"use this tool when you have given a platform name, idea or platform link and you want to find more information about CEO of platform and proposed idea\"\n",
    "    def _run(self, website):\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"sonar-pro\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You are artificial intelligence agent which extracts an information by searching about it online\"\n",
    "                        \"and returns information strictly in the following structured JSON format if it exists:\"\n",
    "                        \"{\"\n",
    "                        \"  'Title of website or platform': <title_of_platform>,\"\n",
    "                        \"  'Proposed Idea': <proposed_idea>,\"\n",
    "                        \"  'CEO Info': <ceo_info>\"\n",
    "                        \"}\"\n",
    "                        \"Please make sure the response has proper line breaks, no extra spaces, unexpected characters (like \\\\n, extra quotes), or non-escaped characters.\"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"I am giving you platform name,idea or platform link and you have to find latest information about\" \n",
    "                        \"the platform by going to given link and return atleast 200 words description about idea and\"\n",
    "                        \"atleast 150 words description about CEO, their goal and achievements\"\n",
    "                        \"Please try to make it as detailed as you can and always refer to online information\"\n",
    "                        \"here is the platform link or name \"\n",
    "                        f\"{str(website)}\"\n",
    "                    )\n",
    "                },\n",
    "            ],\n",
    "        }\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"Authorization\":f\"Bearer {constants.PERPLEXITY_API_KEY}\"\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=headers).json()\n",
    "        return  response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    def _arun(self, website):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetPlatformInfo(BaseTool):\n",
    "    name: str = \"Platform info extractor\"\n",
    "    description: str = \"use this tool when you have given a description about meeting and you have to find the proposed idea, client name or platform link from given description\"\n",
    "\n",
    "    def _run(self, description):\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"sonar-pro\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You have given a description of meeting and you will have to find out proposed idea, client name and website link mentioned in the given description.\"\n",
    "                        \"Use client info extractor tool to get more information.\"\n",
    "                        \"Return it strictly in the following structured JSON format: \"\n",
    "                        \"{\"\n",
    "                        \"  'Idea': <idea>,\"\n",
    "                        \"  'Client Info': <client_info>,\"\n",
    "                        \"  'Platform Link': <platform_link>\"\n",
    "                        \"}\"\n",
    "                        \"Please make sure the response has proper line breaks, no extra spaces, unexpected characters (like \\\\n, extra quotes), or non-escaped characters.\"\n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"if anything is not provided in description then use internet and google search to find out the actual information\"\n",
    "                        \"Here is the meeting description \" \n",
    "                        f\"{str(description)}\"\n",
    "                    )\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"Authorization\":f\"Bearer {constants.PERPLEXITY_API_KEY}\"\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=headers).json()\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    def _arun(self, website):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetIdeaSolution(BaseTool):\n",
    "    name: str = \"Solution extractor\"\n",
    "    description: str = \"use this tool when you have given an idea description and information about client and you have to find solution on how we can achieve the given idea\"\n",
    "\n",
    "    def _run(self, description):\n",
    "        url = \"https://api.perplexity.ai/chat/completions\"\n",
    "        payload = {\n",
    "            \"model\": \"sonar-pro\",\n",
    "            \"messages\": [\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": (\n",
    "                        \"You have given an idea description and you have to find a solution to achieve the given idea using AI-ML\"\n",
    "                        \"or webdev technologies. Search online about tech stack, resources, timeline of project and youtube videos and send it with proper formatting strictly in the following structured JSON format with proper line breaks, no extra spaces, unexpected characters (e.g., \\\\n, extra quotes, unescaped characters), and proper escaping. \"\n",
    "                        \"Ensure the response has the following format: \"\n",
    "                        \"{\"\n",
    "                        \"  'Solution': <solution>,\"\n",
    "                        \"  'Tech Stack': <tech_stack>,\"\n",
    "                        \"  'Timeline': <timeline>\"\n",
    "                        \"}\"  \n",
    "                    ),\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": (\n",
    "                        \"Here is the idea description: \" \n",
    "                        f\"{str(description)}\"\n",
    "                    )\n",
    "                },\n",
    "            ]\n",
    "        }\n",
    "        headers = {\n",
    "            \"accept\": \"application/json\",\n",
    "            \"content-type\": \"application/json\",\n",
    "            \"Authorization\":f\"Bearer {constants.PERPLEXITY_API_KEY}\"\n",
    "        }\n",
    "        response = requests.post(url, json=payload, headers=headers).json()\n",
    "        return response[\"choices\"][0][\"message\"][\"content\"]\n",
    "    \n",
    "    def _arun(self, website):\n",
    "        raise NotImplementedError(\"This tool does not support async\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Βασίλης\\AppData\\Local\\Temp\\ipykernel_12580\\1857880921.py:4: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# Creating Agent\n",
    "from langchain.agents import initialize_agent\n",
    "tools = [GetClientDetails(), GetPlatformInfo(), GetIdeaSolution()]\n",
    "agent = initialize_agent(\n",
    "    tools=tools, \n",
    "    llm = llm, \n",
    "    agent=\"zero-shot-react-description\", \n",
    "    verbose=True, \n",
    "    max_iterations=3, \n",
    "    early_stopping_method='generate', \n",
    "    memory = conversational_memory, \n",
    "    handle_parsing_errors=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'idea_info': True, 'client_info': False, 'valid': False}\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import re\n",
    "\n",
    "def process_description(description:str):\n",
    "    client = OpenAI(api_key=constants.OPENAI_API_KEY)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        You are an AI assistant that evaluates descriptions of client requests.\n",
    "        \n",
    "        A valid description must contain:\n",
    "        - Information about the IDEA (what the project is about, how it works, or its purpose).\n",
    "        - Information about the CLIENT (who is the client that has the proposed project idea).\n",
    "        \n",
    "        Given the following description, assess whether both criteria are met. \n",
    "        If the idea is present, return 'idea_info': True; otherwise, False.\n",
    "        If the client info is present, return 'client_info': True; otherwise, False.\n",
    "        Also, return 'valid': True if both are present; otherwise, False.\n",
    "\n",
    "        Here is the description: {description}\n",
    "\n",
    "        Provide the result in valid JSON format with keys: 'idea_info', 'client_info', 'valid'. Make sure to use proper line breaks and no extra spaces.\n",
    "    \"\"\"\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful AI assistant that processes and evaluates project description from user\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "    )\n",
    "    result_text = chat_completion.choices[0].message.content\n",
    "\n",
    "    # Regex pattern to extract the JSON object from the response\n",
    "    pattern = r\"\\{[^{}]*\\}\"\n",
    "\n",
    "    match = re.search(pattern, result_text, re.DOTALL)  # DOTALL allows matching across multiple lines\n",
    "    result_json = match.group(0)\n",
    "    return json.loads(result_json)\n",
    "\n",
    "# Example Usage\n",
    "user_input = \"An AI-powered chatbot.\"\n",
    "result = process_description(user_input)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Βασίλης\\AppData\\Local\\Temp\\ipykernel_6564\\3114174648.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  para = agent.run(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mTo answer this question, I need to follow a series of steps to extract the necessary information and structure it as requested. \n",
      "\n",
      "First, I will use the Platform info extractor tool to find the proposed idea, client name, and platform link from the given description.\n",
      "\n",
      "Action: Platform info extractor\n",
      "Action Input: \"Hey there, myself rohan and we are hosting this meeting to discuss about my idea of making a twitter automation tool with several features like automated tweets, scheduled tweets, tweet improvement guides etc\"\u001b[0m\n",
      "Observation: \u001b[33;1m\u001b[1;3m{\n",
      "  \"Idea\": \"Making a Twitter automation tool with features like automated tweets, scheduled tweets, and tweet improvement guides\",\n",
      "  \"Client Info\": \"Rohan\",\n",
      "  \"Platform Link\": null\n",
      "}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mNow that I have the idea and client information, I need to find more information about the CEO (Rohan) and the proposed idea, including the product, goals, and achievements of the CEO. I will use the Client details extractor tool for this purpose.\n",
      "\n",
      "Action: Client details extractor\n",
      "Action Input: \"Making a Twitter automation tool with features like automated tweets, scheduled tweets, and tweet improvement guides\"\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3m{\n",
      "  \"Title of website or platform\": \"Twitter Automation Tool\",\n",
      "  \"Proposed Idea\": \"The proposed Twitter automation tool aims to streamline and enhance social media management for businesses and individuals. Key features include automated tweet scheduling, allowing users to plan and queue posts in advance to maintain a consistent online presence. The tool offers smart scheduling capabilities, analyzing follower activity patterns to determine optimal posting times for maximum engagement. Another core feature is the tweet improvement guide, which provides AI-powered suggestions to enhance tweet content, including hashtag recommendations, optimal character count, and engagement-boosting tips. The platform also includes a bulk upload feature for scheduling multiple tweets simultaneously, saving time for users managing high-volume accounts. Additionally, the tool offers analytics and reporting functions to track tweet performance, follower growth, and engagement metrics. To ensure compliance with Twitter's policies, the system includes safeguards against duplicate content and excessive posting. The platform is designed with a user-friendly interface, making it accessible for both social media professionals and casual users looking to improve their Twitter strategy.\",\n",
      "  \"CEO Info\": \"As this is a proposed tool rather than an existing company, there is no specific CEO information available. However, the concept of Twitter automation tools is well-established in the social media management industry. Leaders in this space typically have backgrounds in software development, digital marketing, or social media strategy. Their goals often include simplifying social media management, improving user engagement, and helping businesses maximize their online presence. Achievements for CEOs in this field might include developing innovative features that set their tools apart from competitors, securing partnerships with major brands or influencers, and demonstrating measurable improvements in client engagement metrics. They may also focus on staying ahead of Twitter's evolving algorithms and policies to ensure their tools remain effective and compliant.\"\n",
      "}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mI now have the information about the proposed idea and some general insights into the potential CEO profile for a Twitter automation tool. Next, I need to find how we can help them build this tool, focusing on fetching real-time data from the internet, and provide a detailed solution.\n",
      "\n",
      "Action: Solution extractor\n",
      "Action Input: \"The proposed Twitter automation tool aims to streamline and enhance social media management for businesses and individuals. Key features include automated tweet scheduling, smart scheduling capabilities, tweet improvement guides, bulk upload for scheduling multiple tweets, and analytics and reporting functions. The tool should ensure compliance with Twitter's policies and offer a user-friendly interface.\"\u001b[0m\n",
      "Observation: \u001b[38;5;200m\u001b[1;3m{\n",
      "\"Solution\": \"To develop the proposed Twitter automation tool, we'll create a web application with a robust backend and intuitive frontend. The backend will handle API interactions with Twitter, data processing, and machine learning tasks, while the frontend will provide a user-friendly interface for managing automation features. Key components include:\\n\\n1. Tweet Scheduler: Develop an algorithm to schedule tweets at optimal times based on user preferences and audience engagement patterns.\\n\\n2. Smart Scheduling: Implement machine learning models to analyze historical engagement data and suggest optimal posting times.\\n\\n3. Tweet Improvement Guide: Use natural language processing (NLP) to analyze tweet content and provide suggestions for improvement, such as hashtag recommendations and readability enhancements.\\n\\n4. Bulk Upload: Create a feature to import and schedule multiple tweets from CSV or Excel files.\\n\\n5. Analytics Dashboard: Develop a comprehensive analytics system to track tweet performance, audience growth, and engagement metrics.\\n\\n6. Twitter API Integration: Ensure seamless integration with Twitter's API for posting tweets and retrieving analytics data.\\n\\n7. Policy Compliance: Implement checks to ensure all automated actions comply with Twitter's policies and rate limits.\",\n",
      "\n",
      "\"Tech Stack\": \"Backend:\\n- Python (Django or Flask framework)\\n- PostgreSQL for database\\n- Celery for task queue and scheduling\\n- Redis for caching\\n\\nFrontend:\\n- React.js for user interface\\n- Redux for state management\\n- Material-UI or Tailwind CSS for styling\\n\\nMachine Learning:\\n- TensorFlow or PyTorch for ML models\\n- NLTK or spaCy for NLP tasks\\n\\nAPI Integration:\\n- Tweepy library for Twitter API interactions\\n\\nDeployment:\\n- Docker for containerization\\n- AWS or Google Cloud Platform for hosting\\n- Nginx as reverse proxy\\n\\nMonitoring and Logging:\\n- ELK Stack (Elasticsearch, Logstash, Kibana)\\n\\nVersion Control:\\n- Git and GitHub\",\n",
      "\n",
      "\"Timeline\": \"1. Planning and Requirements Gathering: 2 weeks\\n2. Backend Development:\\n   - Core functionality and database setup: 4 weeks\\n   - Twitter API integration: 2 weeks\\n   - Machine learning model development: 3 weeks\\n3. Frontend Development:\\n   - User interface design: 2 weeks\\n   - Implementation of React components: 4 weeks\\n4. Integration and Testing:\\n   - Backend-frontend integration: 2 weeks\\n   - Unit and integration testing: 2 weeks\\n5. Analytics Dashboard Development: 3 weeks\\n6. Security Implementation and Policy Compliance: 2 weeks\\n7. User Acceptance Testing and Bug Fixes: 2 weeks\\n8. Deployment and Final Testing: 1 week\\n\\nTotal estimated timeline: 24-28 weeks (6-7 months)\"\n",
      "}\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3mFinal Answer:\n",
      "```json\n",
      "{\n",
      "  \"platform_name\": \"Twitter Automation Tool\",\n",
      "  \"CEO_Info\": \"As this is a proposed tool rather than an existing company, there is no specific CEO information available. However, the concept of Twitter automation tools is well-established in the social media management industry. Leaders in this space typically have backgrounds in software development, digital marketing, or social media strategy. Their goals often include simplifying social media management, improving user engagement, and helping businesses maximize their online presence. Achievements for CEOs in this field might include developing innovative features that set their tools apart from competitors, securing partnerships with major brands or influencers, and demonstrating measurable improvements in client engagement metrics. They may also focus on staying ahead of Twitter's evolving algorithms and policies to ensure their tools remain effective and compliant.\",\n",
      "  \"CEO_Name\": \"Rohan\",\n",
      "  \"idea\": \"The proposed Twitter automation tool aims to streamline and enhance social media management for businesses and individuals. Key features include automated tweet scheduling, allowing users to plan and queue posts in advance to maintain a consistent online presence. The tool offers smart scheduling capabilities, analyzing follower activity patterns to determine optimal posting times for maximum engagement. Another core feature is the tweet improvement guide, which provides AI-powered suggestions to enhance tweet content, including hashtag recommendations, optimal character count, and engagement-boosting tips. The platform also includes a bulk upload feature for scheduling multiple tweets simultaneously, saving time for users managing high-volume accounts. Additionally, the tool offers analytics and reporting functions to track tweet performance, follower growth, and engagement metrics. To ensure compliance with Twitter's policies, the system includes safeguards against duplicate content and excessive posting. The platform is designed with a user-friendly interface, making it accessible for both social media professionals and casual users looking to improve their Twitter strategy.\",\n",
      "  \"solution\": \"To develop the proposed Twitter automation tool, we'll create a web application with a robust backend and intuitive frontend. The backend will handle API interactions with Twitter, data processing, and machine learning tasks, while the frontend will provide a user-friendly interface for managing automation features. Key components include:\\n\\n1. Tweet Scheduler: Develop an algorithm to schedule tweets at optimal times based on user preferences and audience engagement patterns.\\n\\n2. Smart Scheduling: Implement machine learning models to analyze historical engagement data and suggest optimal posting times.\\n\\n3. Tweet Improvement Guide: Use natural language processing (NLP) to analyze tweet content and provide suggestions for improvement, such as hashtag recommendations and readability enhancements.\\n\\n4. Bulk Upload: Create a feature to import and schedule multiple tweets from CSV or Excel files.\\n\\n5. Analytics Dashboard: Develop a comprehensive analytics system to track tweet performance, audience growth, and engagement metrics.\\n\\n6. Twitter API Integration: Ensure seamless integration with Twitter's API for posting tweets and retrieving analytics data.\\n\\n7. Policy Compliance: Implement checks to ensure all automated actions comply with Twitter's policies and rate limits.\",\n",
      "  \"tech_stack\": \"Backend:\\n- Python (Django or Flask framework)\\n- PostgreSQL for database\\n- Celery for task queue and scheduling\\n- Redis for caching\\n\\nFrontend:\\n- React.js for user interface\\n- Redux for state management\\n- Material-UI or Tailwind CSS for styling\\n\\nMachine Learning:\\n- TensorFlow or PyTorch for ML models\\n- NLTK or spaCy for NLP tasks\\n\\nAPI Integration:\\n- Tweepy library for Twitter API interactions\\n\\nDeployment:\\n- Docker for containerization\\n- AWS or Google Cloud Platform for hosting\\n- Nginx as reverse proxy\\n\\nMonitoring and Logging:\\n- ELK Stack (Elasticsearch, Logstash, Kibana)\\n\\nVersion Control:\\n- Git and GitHub\",\n",
      "  \"timeline\": \"1. Planning and Requirements Gathering: 2 weeks\\n2. Backend Development:\\n   - Core functionality and database setup: 4 weeks\\n   - Twitter API integration: 2 weeks\\n   - Machine learning model development: 3 weeks\\n3. Frontend Development:\\n   - User interface design: 2 weeks\\n   - Implementation of React components: 4 weeks\\n4. Integration and Testing:\\n   - Backend-frontend integration: 2 weeks\\n   - Unit and integration testing: 2 weeks\\n5. Analytics Dashboard Development: 3 weeks\\n6. Security Implementation and Policy Compliance: 2 weeks\\n7. User Acceptance Testing and Bug Fixes: 2 weeks\\n8. Deployment and Final Testing: 1 week\\n\\nTotal estimated timeline: 24-28 weeks (6-7 months)\",\n",
      "  \"Platform_link\": null\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "```json\n",
      "{\n",
      "  \"platform_name\": \"Twitter Automation Tool\",\n",
      "  \"CEO_Info\": \"As this is a proposed tool rather than an existing company, there is no specific CEO information available. However, the concept of Twitter automation tools is well-established in the social media management industry. Leaders in this space typically have backgrounds in software development, digital marketing, or social media strategy. Their goals often include simplifying social media management, improving user engagement, and helping businesses maximize their online presence. Achievements for CEOs in this field might include developing innovative features that set their tools apart from competitors, securing partnerships with major brands or influencers, and demonstrating measurable improvements in client engagement metrics. They may also focus on staying ahead of Twitter's evolving algorithms and policies to ensure their tools remain effective and compliant.\",\n",
      "  \"CEO_Name\": \"Rohan\",\n",
      "  \"idea\": \"The proposed Twitter automation tool aims to streamline and enhance social media management for businesses and individuals. Key features include automated tweet scheduling, allowing users to plan and queue posts in advance to maintain a consistent online presence. The tool offers smart scheduling capabilities, analyzing follower activity patterns to determine optimal posting times for maximum engagement. Another core feature is the tweet improvement guide, which provides AI-powered suggestions to enhance tweet content, including hashtag recommendations, optimal character count, and engagement-boosting tips. The platform also includes a bulk upload feature for scheduling multiple tweets simultaneously, saving time for users managing high-volume accounts. Additionally, the tool offers analytics and reporting functions to track tweet performance, follower growth, and engagement metrics. To ensure compliance with Twitter's policies, the system includes safeguards against duplicate content and excessive posting. The platform is designed with a user-friendly interface, making it accessible for both social media professionals and casual users looking to improve their Twitter strategy.\",\n",
      "  \"solution\": \"To develop the proposed Twitter automation tool, we'll create a web application with a robust backend and intuitive frontend. The backend will handle API interactions with Twitter, data processing, and machine learning tasks, while the frontend will provide a user-friendly interface for managing automation features. Key components include:\\n\\n1. Tweet Scheduler: Develop an algorithm to schedule tweets at optimal times based on user preferences and audience engagement patterns.\\n\\n2. Smart Scheduling: Implement machine learning models to analyze historical engagement data and suggest optimal posting times.\\n\\n3. Tweet Improvement Guide: Use natural language processing (NLP) to analyze tweet content and provide suggestions for improvement, such as hashtag recommendations and readability enhancements.\\n\\n4. Bulk Upload: Create a feature to import and schedule multiple tweets from CSV or Excel files.\\n\\n5. Analytics Dashboard: Develop a comprehensive analytics system to track tweet performance, audience growth, and engagement metrics.\\n\\n6. Twitter API Integration: Ensure seamless integration with Twitter's API for posting tweets and retrieving analytics data.\\n\\n7. Policy Compliance: Implement checks to ensure all automated actions comply with Twitter's policies and rate limits.\",\n",
      "  \"tech_stack\": \"Backend:\\n- Python (Django or Flask framework)\\n- PostgreSQL for database\\n- Celery for task queue and scheduling\\n- Redis for caching\\n\\nFrontend:\\n- React.js for user interface\\n- Redux for state management\\n- Material-UI or Tailwind CSS for styling\\n\\nMachine Learning:\\n- TensorFlow or PyTorch for ML models\\n- NLTK or spaCy for NLP tasks\\n\\nAPI Integration:\\n- Tweepy library for Twitter API interactions\\n\\nDeployment:\\n- Docker for containerization\\n- AWS or Google Cloud Platform for hosting\\n- Nginx as reverse proxy\\n\\nMonitoring and Logging:\\n- ELK Stack (Elasticsearch, Logstash, Kibana)\\n\\nVersion Control:\\n- Git and GitHub\",\n",
      "  \"timeline\": \"1. Planning and Requirements Gathering: 2 weeks\\n2. Backend Development:\\n   - Core functionality and database setup: 4 weeks\\n   - Twitter API integration: 2 weeks\\n   - Machine learning model development: 3 weeks\\n3. Frontend Development:\\n   - User interface design: 2 weeks\\n   - Implementation of React components: 4 weeks\\n4. Integration and Testing:\\n   - Backend-frontend integration: 2 weeks\\n   - Unit and integration testing: 2 weeks\\n5. Analytics Dashboard Development: 3 weeks\\n6. Security Implementation and Policy Compliance: 2 weeks\\n7. User Acceptance Testing and Bug Fixes: 2 weeks\\n8. Deployment and Final Testing: 1 week\\n\\nTotal estimated timeline: 24-28 weeks (6-7 months)\",\n",
      "  \"Platform_link\": null\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "para = agent.run(\n",
    "      \"First find the idea, client name and platform link using Platform info extractor tool and find 150 words information about proposed idea about product, goals and achievements of CEO. Once you got the information about their idea then find how we can help them to build it in 200 words \"\n",
    "      \"fetch realtime data from internet everytime.\"\n",
    "      \"This information is going to be added in project proposal so please write in detail and sections like CEO_Info,idea and solution must be explained in 600 words each. \"\n",
    "      \"Return your response in structured JSON format like below and please use proper line breaks: \"\n",
    "      \"\"\"\n",
    "      {\n",
    "      \"platform_name\": <platform_name>,\n",
    "      \"CEO_Info\": <ceo_info>,\n",
    "      \"CEO_Name\": <ceo_name>,\n",
    "      \"idea\": <idea>,\n",
    "      \"solution\": <solution>,\n",
    "      \"tech_stack\": <tech stack>,\n",
    "      \"timeline\": <timeline>,\n",
    "      \"Platform_link\": <platform_link>\n",
    "      }\n",
    "      \"\"\"\n",
    "      \"Here is the description: \"\n",
    "      \"Hey there, myself rohan and we are hosting this meeting to discuss about my idea of making a twitter automation tool with several features like automated tweets, scheduled tweets, tweet improvement guides etc\"\n",
    "      )\n",
    "print(para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Project name \n",
      "Twitter Automation Tool\n",
      "\n",
      "# Who is client? \n",
      "The Twitter Automation Tool is a conceptual project designed to serve businesses and individuals who seek to enhance their social media management capabilities. Although there is no specific client or CEO since this is a proposed tool rather than an existing company, the project is rooted in the well-established domain of social media management. Leaders in this space typically have backgrounds in software development, digital marketing, and social media strategy. Their primary objectives include simplifying social media tasks, improving user engagement, and maximizing the online presence of businesses and individuals. Achievements for professionals in this field often involve developing innovative features that distinguish their tools from competitors, securing partnerships with major brands or influencers, and demonstrating measurable improvements in client engagement metrics. Additionally, they focus on staying ahead of Twitter's evolving algorithms and policies to ensure their tools remain effective and compliant.\n",
      "\n",
      "# What is the idea? \n",
      "The core idea behind the proposed Twitter Automation Tool is to streamline and enhance social media management for businesses and individuals. The tool is envisioned to offer a comprehensive suite of features designed to optimize the Twitter experience. Key functionalities include automated tweet scheduling, enabling users to plan and queue posts in advance for a consistent online presence. The tool will feature smart scheduling capabilities, analyzing follower activity patterns to determine optimal posting times for maximum engagement. A standout feature is the tweet improvement guide, which utilizes AI-powered suggestions to enhance tweet content, including hashtag recommendations, optimal character count, and engagement-boosting tips. The platform also includes a bulk upload feature for scheduling multiple tweets simultaneously, saving time for users managing high-volume accounts. Additionally, the tool provides robust analytics and reporting functions to track tweet performance, follower growth, and engagement metrics. To ensure compliance with Twitter's policies, the system incorporates safeguards against duplicate content and excessive posting. The platform is designed with a user-friendly interface, making it accessible for both social media professionals and casual users seeking to refine their Twitter strategy.\n",
      "\n",
      "# How can we help? \n",
      "To bring the proposed Twitter Automation Tool to life, a comprehensive development approach is necessary. The solution involves creating a web application with a robust backend and intuitive frontend. The backend will handle API interactions with Twitter, data processing, and machine learning tasks, while the frontend will provide a user-friendly interface for managing automation features. Key components of the solution include:\n",
      "\n",
      "1. **Tweet Scheduler**: An algorithm will be developed to schedule tweets at optimal times based on user preferences and audience engagement patterns.\n",
      "   \n",
      "2. **Smart Scheduling**: Machine learning models will be implemented to analyze historical engagement data and suggest optimal posting times.\n",
      "\n",
      "3. **Tweet Improvement Guide**: Natural Language Processing (NLP) will be utilized to analyze tweet content and provide suggestions for improvement, such as hashtag recommendations and readability enhancements.\n",
      "\n",
      "4. **Bulk Upload**: A feature will be created to import and schedule multiple tweets from CSV or Excel files.\n",
      "\n",
      "5. **Analytics Dashboard**: A comprehensive analytics system will be developed to track tweet performance, audience growth, and engagement metrics.\n",
      "\n",
      "6. **Twitter API Integration**: Seamless integration with Twitter's API will be ensured for posting tweets and retrieving analytics data.\n",
      "\n",
      "7. **Policy Compliance**: Checks will be implemented to ensure all automated actions comply with Twitter's policies and rate limits.\n",
      "\n",
      "Overall, our team is committed to developing a tool that not only enhances Twitter management efficiency but also adheres to the highest standards of compliance and user experience.\n",
      "\n",
      "# Tech stack\n",
      "The development of the Twitter Automation Tool will leverage a modern tech stack that ensures scalability, efficiency, and ease of use:\n",
      "\n",
      "**Backend**:\n",
      "- Python (Django or Flask framework)\n",
      "- PostgreSQL for database management\n",
      "- Celery for task queue and scheduling\n",
      "- Redis for caching\n",
      "\n",
      "**Frontend**:\n",
      "- React.js for building the user interface\n",
      "- Redux for state management\n",
      "- Material-UI or Tailwind CSS for styling\n",
      "\n",
      "**Machine Learning**:\n",
      "- TensorFlow or PyTorch for developing machine learning models\n",
      "- NLTK or spaCy for NLP tasks\n",
      "\n",
      "**API Integration**:\n",
      "- Tweepy library for seamless Twitter API interactions\n",
      "\n",
      "**Deployment**:\n",
      "- Docker for containerization\n",
      "- AWS or Google Cloud Platform for reliable hosting\n",
      "- Nginx as a reverse proxy\n",
      "\n",
      "**Monitoring and Logging**:\n",
      "- ELK Stack (Elasticsearch, Logstash, Kibana) for comprehensive monitoring and logging\n",
      "\n",
      "**Version Control**:\n",
      "- Git and GitHub for efficient version control and collaboration\n",
      "\n",
      "# Timeline \n",
      "The development and deployment of the Twitter Automation Tool are estimated to span 24-28 weeks (6-7 months). The timeline is structured as follows:\n",
      "\n",
      "1. **Planning and Requirements Gathering**: 2 weeks\n",
      "\n",
      "2. **Backend Development**:\n",
      "   - Core functionality and database setup: 4 weeks\n",
      "   - Twitter API integration: 2 weeks\n",
      "   - Machine learning model development: 3 weeks\n",
      "\n",
      "3. **Frontend Development**:\n",
      "   - User interface design: 2 weeks\n",
      "   - Implementation of React components: 4 weeks\n",
      "\n",
      "4. **Integration and Testing**:\n",
      "   - Backend-frontend integration: 2 weeks\n",
      "   - Unit and integration testing: 2 weeks\n",
      "\n",
      "5. **Analytics Dashboard Development**: 3 weeks\n",
      "\n",
      "6. **Security Implementation and Policy Compliance**: 2 weeks\n",
      "\n",
      "7. **User Acceptance Testing and Bug Fixes**: 2 weeks\n",
      "\n",
      "8. **Deployment and Final Testing**: 1 week\n",
      "\n",
      "The timeline allows for thorough testing and refinement, ensuring a high-quality product launch. Our team is dedicated to meeting these milestones and delivering a robust tool that meets the needs of its users.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI(api_key = constants.OPENAI_API_KEY)\n",
    "chat_completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o\",\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"\"\"\n",
    "                I am giving you some data in python dictionary format and you will have to add more information in it and convert it in markdown file with below format\n",
    "                Don't use anything except headings and paragraphs in markdown \n",
    "                # Project name \n",
    "                <project_name>\n",
    "                # Who is client? \n",
    "                <information about client>\n",
    "                # What is the idea? \n",
    "                <information about idea>\n",
    "                # How can we help? \n",
    "                <detailed information about solution>\n",
    "                # Tech stack\n",
    "                <information about tech stack>\n",
    "                # Timeline \n",
    "                <information about timeline>\n",
    "                Try to add more information by yourself too to make it more detailed and make it around 800 words. Don't return anything except markdown and use proper line breaks.\n",
    "                Here is the information about fields in the given dictionary:\n",
    "                platform_name: Name of platform\n",
    "                CEO_Info: Background about CEO and information about CEO \n",
    "                CEO_Name: Name of CEO\n",
    "                idea: project idea \n",
    "                solution: solution on how we can solve the given problem statement and how to achieve the given idea \n",
    "                tech_stack: technology stack used  to build the solution \n",
    "                timeline: timeline of the project \n",
    "                Platform_link: link to the platform \n",
    "                Here is the data:\n",
    "                {para}\n",
    "            \"\"\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "output = chat_completion.choices[0].message.content\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pypandoc\n",
    "output = pypandoc.convert_text(output, 'docx', format='md', outputfile=\"output.docx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
